# B.A.R.S. Parsik - Parser - Parsor
## Описание - Что, Зачем.
### Что
Парсинг сайтов – последовательный синтаксический анализ и сбор информации, размещённой на интернет-страницах. Что представляет из себя текст интернет-страниц? Иерархичный набор данных, структурированный с помощью человеческих и компьютерных языков. На человеческом языке предоставлена информация, знания, ради которых, собственно, люди и пользуются Интернетом.
### Зачем
Создавая веб-сайт, его владелец неизбежно сталкивается с проблемой – где брать контент? Оптимальный вариант: найти информацию там где её очень много – в Интернете. Но при этом приходится решать такие задачи:

* __Большие объёмы__. В эпоху бурного роста Сети и жесточайшей конкуренции уже всем ясно, что успешный веб-проект немыслим без размещения большого количества информации на сайте. Современные темпы жизни приводят к тому, что контента должно быть не просто много, а очень много, в количествах, намного превышающих пределы, возможные при ручном заполнении.

* __Частое обновление__. Обслуживание огромного потока динамично меняющейся информации не в силах обеспечить один человек или даже слаженная команда операторов. Порой информация изменяется ежеминутно и в ручном режиме обновлять её вряд ли целесообразно.

Парсинг сайтов является эффективным решением для автоматизации сбора и изменения информации.

По сравнению с человеком, компьютерная программа-парсер:

1. *__быстро__* обойдет тысячи веб-страниц;
2. *__аккуратно__* отделит техническую информацию от «человеческой»;
3. *__безошибочно__* отберёт нужное и отбросит лишнее;
4. *__эффективно__* упакует конечные данные в необходимом виде.

Результат (будь то база данных или электронная таблица), конечно же, нуждается в дальнейшей обработке. Впрочем, последующие манипуляции с собранной информацией уже к теме парсинга не относятся.

## Что уже умеет и как работает наш сервис.
Сервис работает по инструкции - которая представляет собой json (текстовый) - файл.

Инструкция содержит в себе:
* Адрес сайта - который мы хотим спарсить.
* _Описанные_ действия _виртуального пользователя_(бот-парсера).

Парсер __может__:
* собрать любую информацию по __указанным нами ранее__ фильтрам. (собрать - _сохранить у себя_ на жестком диске).
* агрегировать собранную информацию (объеденить не типизированные данные из одной предметной области).
* анализировать собранную информацию.
* преобразовать её в нужный формат.
* отправить по указанному адресу собранную инфу.
* проводить описанные выше процедуры по _таймеру_ (возможность настройки расписания задач).
* может собирать информацию из нескольких сайтов (поочередно), и постить его в соц.сети, на другие сайты, отправлять по почте.

Парсер __не может__ (_пока_):
* искать информацию по заданному запросу _без списка сайтов указанного ранее_.
* _смотреть_ в режиме он-лайн на интересующую нас информацию и анализировать её _на лету_ - (инфу __необходимо__ _собирать_).

## Кейсы (примеры использования):
1. Собрать контактные данные по пользователям в Фейсбуке. Алгоритм работы:
   * Парсер вбивает заданный поисковый запрос типа фрагмента названия группы - в строку поиска соц.сети.
   * Выполняет этот запрос и собирает ссылки на все найденные группы.
   * Заходит по собранной ссылке в каждую группу, переходит в "Участники".
   * Собирает ссылки на каждого участника.
   * Заходит по ссылке на страницу каждого участника.
   * Собирает необходимую нам информацию по участнику.

2. Собрать информацию по заданному поисковому запросу на продуктовой платформе и разместить её на указанном сайте, группе соц.сети
   * Парсер вбивает текст запроса в строку поиска продуктовой платформы.
   * Собирает ссылки всех продуктов показанных в результате запроса.
   * Проходит по собранным ссылкам и сохраняет у себя (локально, на жестком диске) информацию.
   * Закончив сбор информации. Переходит по указанной ссылке на наш сайт, группу, т.п..
   * Начинает поочередно постить собранную информацию в соответствующие поля страницы редактирования на сайте, либо может по API (интерфейс взаимодейсвия) передавать полученную информацию на сайт, группу.

3. Собрать информацию из разных источников, например разных риелторских сайтов, указанных ранее. И разместить её в одном месте. (Аггрегация данных). Алгоритм подобен описанным выше.

4. Выполнять любую циклическую работу которую можно формализировать в жесткой последовательности. (Удачнее формулировку пока не придумал).
